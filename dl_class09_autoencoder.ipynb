{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Course: Deep Learning\n",
        "# Author: Sandro Camargo sandrocamargo@unipampa.edu.br\n",
        "# Autoencoder for MNIST\n",
        "\n",
        "Dataset: '/content/sample_data/' mnist\n",
        "\n",
        "Dataset description: https://www.tensorflow.org/datasets/catalog/mnist\n",
        "\n",
        "To open this code in your Google Colab environment, [click here](https://colab.research.google.com/github/Sandrocamargo/deep-learning/blob/master/dl_class09_autoencoder.ipynb).\n"
      ],
      "metadata": {
        "id": "3-_h1i_Ln6BN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading libraries"
      ],
      "metadata": {
        "id": "fekyjgDzoEIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlypMTDLfuum"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "vf6w-IvSoI33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(x_train, _), (x_test, _) = datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Flatten das imagens 28x28 → vetor 784\n",
        "x_train = x_train.reshape((len(x_train), 784))\n",
        "x_test  = x_test.reshape((len(x_test), 784))"
      ],
      "metadata": {
        "id": "RGprxx7Vfx9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting autoencoder"
      ],
      "metadata": {
        "id": "Lw7bk19ToNPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_dim = 32  # Dimensão comprimida\n",
        "\n",
        "# Modelo Autoencoder no estilo Sequential\n",
        "autoencoder = models.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(encoding_dim, activation='relu'),\n",
        "    layers.Dense(784, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Criar um encoder igual, sem compartilhar tensores\n",
        "encoder = models.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(encoding_dim, activation='relu')\n",
        "])\n",
        "\n",
        "#encoding_dim = 32  # Dimensão comprimida (redução de 784 → 32)\n",
        "\n",
        "#input_img = layers.Input(shape=(784,))\n",
        "#encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "#decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "#autoencoder = models.Model(input_img, decoded)\n",
        "\n",
        "# Também criamos o codificador separadamente (para visualização posterior)\n",
        "#encoder = models.Model(input_img, encoded)"
      ],
      "metadata": {
        "id": "Ew89eK_vfzsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling and training"
      ],
      "metadata": {
        "id": "bXePKxy-oQW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.summary()\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    x_train, x_train,\n",
        "    epochs=20,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(x_test, x_test)\n",
        ")"
      ],
      "metadata": {
        "id": "bXzs8Zs3f1dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Viewing loss"
      ],
      "metadata": {
        "id": "18VLEGT5VKJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss Function')\n",
        "plt.ylabel('Categorical Cross Entropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Error','Validation Error'], loc='upper right')\n",
        "plt.savefig(\"trainingerror.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FYD75QOWUHM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Viewing results"
      ],
      "metadata": {
        "id": "hLjzbhfsoW6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar e reconstruir\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Mostrar imagens originais e reconstruídas\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Reconstruída\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Reconstruída\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m5Popp-vf3TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Viewing bootleneck (latent space)"
      ],
      "metadata": {
        "id": "-T-O8gpDofKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1️⃣ Gerar embeddings (gargalo)\n",
        "# ---------------------------------------------------------\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2️⃣ Reduzir para 2D (PCA ou t-SNE)\n",
        "# ---------------------------------------------------------\n",
        "method = \"TSNE\"  # ou \"PCA\"\n",
        "\n",
        "if method == \"PCA\":\n",
        "    reducer = PCA(n_components=2)\n",
        "else:\n",
        "    reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "\n",
        "latent_2d = reducer.fit_transform(encoded_imgs)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3️⃣ Visualizar o espaço latente colorido por rótulo\n",
        "# ---------------------------------------------------------\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(latent_2d[:, 0], latent_2d[:, 1],\n",
        "            s=10, c=y_test, cmap='tab10', alpha=0.8)\n",
        "plt.colorbar(label=\"Dígito real\")\n",
        "plt.title(f\"Espaço Latente do Autoencoder ({method})\")\n",
        "plt.xlabel(\"Dimensão 1\")\n",
        "plt.ylabel(\"Dimensão 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oszeVsDWrLMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}