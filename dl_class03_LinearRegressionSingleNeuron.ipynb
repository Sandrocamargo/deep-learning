{"cells":[{"cell_type":"markdown","metadata":{"id":"9feqnHODNlEV"},"source":["# Course: Deep Learning\n","# Author: Sandro Camargo <sandrocamargo@unipampa.edu.br>\n","# Single Neuron Linear Regression Example\n","# Dataset: https://archive.ics.uci.edu/ml/datasets/Algerian+Forest+Fires+Dataset++"]},{"cell_type":"markdown","metadata":{"id":"NVnjeeftXQl6"},"source":["A Python library is a collection of related functions. A library contains bundles of encapsuated code which can be used repeatedly in different programs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lt7-B5mnWZRb"},"outputs":[],"source":["# Import Libraries\n","import keras # Neural Network Library\n","from keras import layers # Layers to a neural network\n","from keras import optimizers # optimizers\n","import pandas as pd # Data Manipulation library\n","import numpy as np # Fast Numeric Computing library\n","import tensorflow as tf # Optimizers\n","import matplotlib.pyplot as plt # Plot library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":540,"status":"ok","timestamp":1669415602823,"user":{"displayName":"Sandro da Silva Camargo","userId":"06421274945774290776"},"user_tz":180},"id":"pBNiKzKsWtW9","outputId":"0dd5bb73-b1b7-402a-bcec-d62a632d203c"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 243 entries, 0 to 242\n","Data columns (total 13 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   day          243 non-null    int64  \n"," 1   month        243 non-null    int64  \n"," 2   year         243 non-null    int64  \n"," 3   Temperature  243 non-null    int64  \n"," 4    RH          243 non-null    int64  \n"," 5    Ws          243 non-null    int64  \n"," 6   Rain         243 non-null    float64\n"," 7   FFMC         243 non-null    float64\n"," 8   DMC          243 non-null    float64\n"," 9   DC           243 non-null    float64\n"," 10  ISI          243 non-null    float64\n"," 11  BUI          243 non-null    float64\n"," 12  FWI          243 non-null    float64\n","dtypes: float64(7), int64(6)\n","memory usage: 24.8 KB\n"]}],"source":["# Loading dataset\n","data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00547/Algerian_forest_fires_dataset_UPDATE.csv', header=1, skiprows=[124,125,126,170], usecols=list(range(0,13)))\n","# About the parameters\n","# Header=1: column names (day, month, year, ...) are in the line 1 of this CSV file.\n","# skiprows=[124,125,126,170]: this lines, which not contains valid data, are not imported. If this parameter is missing, all lines are imported.\n","# usecols=list(range(0,13)): The last column, which is named Classes, is not imported. If this parameter is missing, all columns are imported.\n","# delimiter=\",\": when the delimiter among columns is not a ;\n","\n","# inspecting columns and data types from \"data\" dataframe\n","data.info()"]},{"cell_type":"markdown","metadata":{"id":"tmq8UTaXdFtF"},"source":["The dataset must be randomly splitted in two parts: training set and testing set. The main approaches to split are holdout and n-fold cross validation.\n","*   Training set is used for building (training) the model.\n","*   Testing set is used for testing the generalization ability of the model built.\n","\n","Moreover, inputs($x$) and outputs($y$) must be splitted in each set.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1669415602825,"user":{"displayName":"Sandro da Silva Camargo","userId":"06421274945774290776"},"user_tz":180},"id":"-vjSR2UWY3gi","outputId":"b93c7c7a-a48d-41f6-d27b-a66d305a46be"},"outputs":[{"output_type":"stream","name":"stdout","text":["The training dataset (inputs) dimensions are:  (188, 12)\n","The training dataset (outputs) dimensions are:  (188, 1)\n","The testing dataset (inputs) dimensions are:  (55, 12)\n","The testing dataset (outputs) dimensions are:  (55, 1)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]}],"source":["np.random.seed(1) # Random numbers will be ever the same\n","rnd = np.random.rand(len(data)) < 0.8 # Training set will contain 80% of the data\n","\n","# Creating the training dataset (80%)\n","train_x = data[rnd]\n","train_x.drop(train_x.columns[[12]], axis=1, inplace=True) # column 12 is removed, because it is the output (y)\n","train_y = data[rnd]\n","train_y.drop(train_y.iloc[:, 0:12], axis=1, inplace=True) # columns from 0 to 11 are removed, because they are the inputs (x)\n","\n","# Creating the testing dataset (20%)\n","test_x = data[~rnd]\n","test_x.drop(test_x.columns[[12]], axis=1, inplace=True)\n","test_y = data[~rnd]\n","test_y.drop(test_y.iloc[:, 0:12], axis=1, inplace=True)\n","\n","# Verifying dataset dimensions\n","print('The training dataset (inputs) dimensions are: ', train_x.shape)\n","print('The training dataset (outputs) dimensions are: ', train_y.shape)\n","print('The testing dataset (inputs) dimensions are: ', test_x.shape)\n","print('The testing dataset (outputs) dimensions are: ', test_y.shape)"]},{"cell_type":"markdown","metadata":{"id":"_8NAHkCSh5sr"},"source":["After creating the datasets, the next step is defining the architecture of our model.\n","\n","It must be defined:\n","\n","\n","*   Architecture: in terms of neurons and layers\n","*   Optimizer: is the algorithm or method used to change the weights in order to minimize the loss function.\n","\n","The last step is compiling the model. In this step the loss function, the optimizer and the evaluation metrics must be defined."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmnZB0CRWVPI"},"outputs":[],"source":["# Function to define model architecture\n","def build_model():\n","  # Defining the architecture\n","  # Sequential = Feedforward Neural Network\n","  # 1 single neuron\n","  # input_shape is the amount of columns from training set\n","  model = keras.Sequential([\n","        layers.Dense(1, input_shape = [len(train_x.columns)])\n","  ])\n","\n","  # Defining the optimizer\n","  optimizer = tf.keras.optimizers.RMSprop(\n","      learning_rate = 0.001)\n","\n","  # Mean Squared Error (MSE) is the default loss function in regression models\n","  model.compile(loss = 'mse',\n","      optimizer = optimizer,\n","      metrics = ['mse','mae'])\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"8ZMgKCn8jouX"},"source":["Just for curiosity, you should observe how many parameters ($\\theta$) your model has.\n","At this point, your model is built."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1669415603099,"user":{"displayName":"Sandro da Silva Camargo","userId":"06421274945774290776"},"user_tz":180},"id":"a0C1tp1naRoS","outputId":"f648171c-1e90-4681-81f6-88f312db23a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 1)                 13        \n","                                                                 \n","=================================================================\n","Total params: 13\n","Trainable params: 13\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = build_model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"SoQyGcmFWOGS"},"source":["After creating the model, it must be trained (fitted).\n","Training is done using training set and the amount of epochs must be defined."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":918},"id":"R-Y4iU2naonL","outputId":"a53362a7-564d-47f0-bb93-7a9f48df8657","executionInfo":{"status":"error","timestamp":1669415603796,"user_tz":180,"elapsed":703,"user":{"displayName":"Sandro da Silva Camargo","userId":"06421274945774290776"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2000\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-67989ec2bacb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 894, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 987, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 480, in update_state\n        self.build(y_pred, y_true)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 398, in build\n        y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 526, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 526, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 545, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics/__init__.py\", line 182, in get\n        return deserialize(str(identifier))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics/__init__.py\", line 142, in deserialize\n        printable_module_name='metric function')\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\", line 710, in deserialize_keras_object\n        f'Unknown {printable_module_name}: {object_name}. Please ensure '\n\n    ValueError: Unknown metric function: r2_score. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"]}],"source":["EPOCHS = 2000\n","\n","history = model.fit(\n","    train_x, train_y, epochs = EPOCHS, verbose = 1\n",")"]},{"cell_type":"markdown","metadata":{"id":"b5znM4xvHLcp"},"source":["This plot should be generated just to inspect the learning convergence.\n","It is expected a decreasing of the loss function value through the epochs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"LfbEFBSHz7KC","executionInfo":{"status":"error","timestamp":1695749196393,"user_tz":180,"elapsed":565,"user":{"displayName":"Sandro da Silva Camargo","userId":"06421274945774290776"}},"colab":{"base_uri":"https://localhost:8080/","height":246},"outputId":"531ba6ad-6e58-4583-b8a6-77609f85d993"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c0fe9c8a4edc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training MSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}],"source":["plt.plot(history.history['mse'])\n","plt.title('Training MSE')\n","plt.ylabel('MSE')\n","plt.xlabel('Epoch')\n","plt.legend(['Error'], loc='upper right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YTqSvbNeOJG5"},"source":["After the training process, the knowledge learnt by a neural network is stored in its weights."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-BJawrri0hA2","executionInfo":{"status":"error","timestamp":1695751053532,"user_tz":180,"elapsed":967,"user":{"displayName":"Sandro da Silva Camargo","userId":"06421274945774290776"}},"outputId":"376d17fa-fb78-4030-e8fd-299dc1778331","colab":{"base_uri":"https://localhost:8080/","height":247}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-02061ff6ecd0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# return a numpy list of weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["weights, biases = model.get_weights() # return a numpy list of weights\n","print(weights)\n","plt.plot(weights)\n","plt.ylabel('Weights')\n","plt.xlabel('Inputs')"]},{"cell_type":"code","source":["plt.barh(train_x.columns, weights[:,0].astype(float), align='center')\n","plt.xlabel(\"Weights\")\n","plt.ylabel(\"Inputs\")\n","#plt.title(target)\n","plt.savefig(\"NN-Weights.png\")"],"metadata":{"id":"mq88J_8a5jCQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J9ZQbtPLOfze"},"source":["After the training process, the model should be tested in order to measure its quality, it means, how good are its predictions. The model must be evaluated using the testing set, which is composed by samples that are not in the training set. In regression problems, the correlation coefficient is the default metric to measure the model quality.\n","The correlation coefficient is computed using real outputs ($y$) and predicted outputs ($\\hat{y}$). Correlation coefficient can vary between 0 (bad predictions) and 1 (perfect predictions)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5PeLuUK06cw"},"outputs":[],"source":["test_predictions = model.predict(test_x).flatten() # predict radon activities with the built linear regression model\n","\n","plt.scatter(test_y, test_predictions, marker = 'o', c = 'blue')\n","plt.plot([-5,35], [-5,35], color = 'black', ls = '--')\n","plt.ylabel('Predictions')\n","plt.xlabel('Real Values')\n","plt.title('Linear Regression with One Neuron (Testing Set)')\n","plt.ylim(-5, 35)\n","plt.xlim(-5, 35)\n","plt.axis(True)\n","plt.show()\n","\n","output = pd.DataFrame.to_numpy(test_y, copy=True)\n","print(\"Correlation Coefficient in testing set: %.4f\" % np.corrcoef(test_predictions, np.transpose(output))[0,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2EHI_hd4OdI"},"outputs":[],"source":["train_predictions = model.predict(train_x).flatten() # predict radom activities with the built linear regression model\n","\n","plt.scatter(train_y, train_predictions, marker = 'o', c = 'blue')\n","plt.plot([-5,35], [-5,35], color = 'black', ls = '--')\n","plt.ylabel('Predictions')\n","plt.xlabel('Real Values')\n","plt.title('Linear Regression with One Neuron (Training Set)')\n","plt.ylim(-5, 35)\n","plt.xlim(-5, 35)\n","plt.axis(True)\n","plt.show()\n","\n","output = pd.DataFrame.to_numpy(train_y, copy=True)\n","print(\"Correlation Coefficient in training set: %.4f\" % np.corrcoef(train_predictions, np.transpose(output))[0,1])"]},{"cell_type":"code","source":["!pip3 install ann_visualizer\n","from ann_visualizer.visualize import ann_viz\n","ann_viz(model, view=True, filename=\"singleneuron-regr\", title=\"Single Neuron Regression Architecture\")"],"metadata":{"id":"gBRpYr6j4aJF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6I1BbgwPO8VaiMXows/wU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}