{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Course: Deep Learning\n",
        "# Author: Sandro Camargo sandrocamargo@unipampa.edu.br\n",
        "# MNIST Classification with $\\ell_2$ Regularization\n",
        "# Dataset: '/content/sample_data/' mnist\n",
        "# Dataset description: https://www.tensorflow.org/datasets/catalog/mnist\n",
        "\n",
        "To open this code in your Google Colab environment, [click here](https://colab.research.google.com/github/Sandrocamargo/deep-learning/blob/master/dl_class06_mnist_regularization.ipynb)."
      ],
      "metadata": {
        "id": "mTOF7Ga2rj92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading libraries"
      ],
      "metadata": {
        "id": "EYNMfeQ0MLhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras import layers, models, optimizers, losses, metrics, regularizers"
      ],
      "metadata": {
        "id": "YObRVOwAppbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining image parameters"
      ],
      "metadata": {
        "id": "9Ax-UQAKMbhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 28 # width and length\n",
        "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
        "image_pixels = image_size * image_size"
      ],
      "metadata": {
        "id": "dWcpJL6lqMQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset from google colab"
      ],
      "metadata": {
        "id": "hZOsy9owMRSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/sample_data/\"\n",
        "train_data = np.loadtxt(data_path + \"mnist_train_small.csv\", delimiter=\",\")\n",
        "test_data = np.loadtxt(data_path + \"mnist_test.csv\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "ZlnpugOlxygP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the inputs in [0,1] range and presenting the input and output dataset dimensions"
      ],
      "metadata": {
        "id": "ECMqliS7Ncyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fac = 0.99 / 255\n",
        "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
        "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01"
      ],
      "metadata": {
        "id": "QzgrNcDtrA2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting inputs and outputs\n",
        "Binarizing outputs\n"
      ],
      "metadata": {
        "id": "pyjIrhuxNzY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.asfarray(train_data[:, :1])\n",
        "test_labels = np.asfarray(test_data[:, :1])\n",
        "print('The training dataset (input) dimensions are: ', train_imgs.shape)\n",
        "print('The training dataset (output) dimensions are: ', train_labels.shape)\n",
        "print('The testing dataset (input) dimensions are: ', test_imgs.shape)\n",
        "print('The testing dataset (output) dimensions are: ',test_labels.shape)\n",
        "\n",
        "train_labels_bin = label_binarize(train_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "test_labels_bin = label_binarize(test_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ],
      "metadata": {
        "id": "T4JFAekQNx-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting the training set\n",
        "\n",
        "Showing the first 20 samples and their labels"
      ],
      "metadata": {
        "id": "fLA8OvdcOQ1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=5, ncols=4, figsize=(28, 28))\n",
        "\n",
        "for i in range(5):\n",
        "  for j in range(4):\n",
        "    img = train_data[i*5+j,range(1,785)].reshape((28,28))\n",
        "    ax[i,j].imshow(img, cmap=\"Greys\")\n",
        "    ax[i,j].title.set_text(\"Number: \" + str(int(train_data[i*5+j,0])))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vzOmfg8Lqjyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating and training the model\n"
      ],
      "metadata": {
        "id": "8kHsz-63OYx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "# L2 Regularization\n",
        "reg = regularizers.l2(l2 = 1e-7)\n",
        "\n",
        "model = models.Sequential([\n",
        "  layers.Input(shape=[image_pixels]),\n",
        "  layers.Dense(128, activation='relu',kernel_regularizer = reg),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(0.001),\n",
        "    loss=losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=[metrics.CategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_imgs, train_labels_bin,\n",
        "    epochs=EPOCHS, verbose=1,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "LC0PARKfLJT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the loss function on training and validation set.\n",
        "\n",
        "The best value for epochs is when the validation loss starts to increase.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "woMalYjqMq_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training error')\n",
        "plt.plot(history.history['val_loss'], label='Validation error')\n",
        "plt.title('Loss Function')\n",
        "plt.ylabel('Categorical Cross Entropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper center')\n",
        "plt.savefig(\"mlp-regul-trainingerror.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nCpVZyJY8fyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the classification accuracy on training and validation sets"
      ],
      "metadata": {
        "id": "X1JVynOHM0b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['categorical_accuracy'], label='Training')\n",
        "plt.plot(history.history['val_categorical_accuracy'], label='Validation')\n",
        "plt.title('Training Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(\"mlp-regul-trainingaccuracy.pdf\")\n",
        "plt.show()\n",
        "print(\"Training Categorical Accuracy:\", round(history.history['categorical_accuracy'][-1],4))\n",
        "print(\"Validation Categorical Accuracy:\", round(history.history['val_categorical_accuracy'][-1],4))"
      ],
      "metadata": {
        "id": "MEQbBkwN9IbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluates performance on test set\n",
        "Presents the classification accuracy"
      ],
      "metadata": {
        "id": "YJCdwH9bKWXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(\n",
        "    test_imgs, test_labels_bin, verbose=1\n",
        ")\n",
        "\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "D3HuDOg2ACgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing the performance on training set\n"
      ],
      "metadata": {
        "id": "QOQGnnPXP4CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_imgs)\n",
        "print(confusion_matrix(test_predictions.argmax(axis=1), test_labels_bin.argmax(axis=1)))\n",
        "print(classification_report(test_predictions.argmax(axis=1), test_labels_bin.argmax(axis=1), target_names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']))"
      ],
      "metadata": {
        "id": "FflqU4YECaPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix Heatmap"
      ],
      "metadata": {
        "id": "kLjtvqCcJ-5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(test_predictions.argmax(axis=1), test_labels_bin.argmax(axis=1))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
        "disp.plot(cmap=\"bwr\")\n",
        "plt.title('Confusion Matrix for Testing Set')\n",
        "plt.savefig(\"confusionmatrix.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X0NiJk_TDqGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reporting some misclassified samples"
      ],
      "metadata": {
        "id": "3E7qikwxD4-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "j = -1\n",
        "\n",
        "fig, ax = plt.subplots(nrows=8, ncols=6, figsize=(28, 28))\n",
        "\n",
        "for k in range(5000):\n",
        "  if test_predictions.argmax(axis=1)[k]!=test_labels_bin.argmax(axis=1)[k]:\n",
        "      if i==8:\n",
        "         break\n",
        "      j = j + 1\n",
        "      img = test_data[k,range(1,785)].reshape((28,28))\n",
        "      ax[i,j].imshow(img, cmap=\"Greys\")\n",
        "      ax[i,j].title.set_text(\"Number: \" + str(int(test_data[k,0])) + \", Predicted:\" + str(test_predictions.argmax(axis=1)[k]))\n",
        "      if j>4:\n",
        "         j = -1\n",
        "         i = i + 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qQwr2H0Ev3YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = list()\n",
        "print(model.layers)\n",
        "for layer in model.layers[1:-1]:\n",
        "    weights = layer.get_weights() # list of numpy arrays\n",
        "    for x in weights:\n",
        "      w.append(x)\n",
        "plt.hist(w, bins=50)\n",
        "plt.xlim((-2,2))\n",
        "plt.title(\"Weights Histogram\")\n",
        "plt.savefig(\"mlp-regul-weights.pdf\")"
      ],
      "metadata": {
        "id": "T0AAK9Dg73Fu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}