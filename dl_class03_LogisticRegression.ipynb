{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Federal University of Pampa <www.unipampa.edu.br>\n",
        "# Course: Deep Learning\n",
        "# Author: Sandro Camargo <sandrocamargo@unipampa.edu.br>\n",
        "# Logistic Regression Example\n",
        "# Dataset: https://archive.ics.uci.edu/dataset/547/algerian+forest+fires+dataset\n",
        "\n",
        "To open this code in your Google Colab environment, [click here](https://colab.research.google.com/github/Sandrocamargo/deep-learning/blob/master/dl_class03_LogisticRegression.ipynb)."
      ],
      "metadata": {
        "id": "9feqnHODNlEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Python library is a collection of related functions. A library contains bundles of encapsuated code which can be used repeatedly in different programs."
      ],
      "metadata": {
        "id": "NVnjeeftXQl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd # Data Manipulation library\n",
        "import numpy as np # Fast Numeric Computing library\n",
        "import tensorflow as tf # Optimizers\n",
        "import matplotlib.pyplot as plt # Plot library\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "lt7-B5mnWZRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00547/Algerian_forest_fires_dataset_UPDATE.csv', header=1, skiprows=[124,125,126,170])\n",
        "# About the parameters\n",
        "# Header=1: column names (day, month, year, ...) are in the line 1 of this CSV file\n",
        "# skiprows=[124,125,126,170]: this lines, which not contains valid data, are not imported. If this parameter is missing, all lines are imported.\n",
        "\n",
        "# inspecting columns and data types from \"data\" dataframe\n",
        "data.info()"
      ],
      "metadata": {
        "id": "pBNiKzKsWtW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store target column in y\n",
        "# Store the inputs in X\n",
        "y = data[data.columns[13]]\n",
        "X = data.drop(columns=data.columns[13])"
      ],
      "metadata": {
        "id": "iWNBr7bcjLik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are whitespaces in target column, is some samples.\n",
        "print(y.value_counts())\n",
        "y = pd.Series(y)\n",
        "y = y.str.strip() # Remove whitespaces from extremes\n",
        "print(y.value_counts())"
      ],
      "metadata": {
        "id": "chQxMKCZAsc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.25,  random_state=1, stratify=y)"
      ],
      "metadata": {
        "id": "75gSUBgWlGTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset must be randomly splitted in two parts: training set and testing set. The main approaches to split are holdout and n-fold cross validation.\n",
        "*   Training set is used for building (training) the model.\n",
        "*   Testing set is used for testing the generalization ability of the model built.\n",
        "\n",
        "Moreover, inputs($x$) and outputs($y$) must be splitted in each set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tmq8UTaXdFtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying dataset dimensions\n",
        "print('The training dataset (inputs) dimensions are: ', train_x.shape)\n",
        "print('The training dataset (outputs) dimensions are: ', train_y.shape)\n",
        "print('The testing dataset (inputs) dimensions are: ', test_x.shape)\n",
        "print('The testing dataset (outputs) dimensions are: ', test_y.shape)"
      ],
      "metadata": {
        "id": "-vjSR2UWY3gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "4b0ZGIkXDGQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_x)\n",
        "y_prob = model.predict_proba(test_x)[:, 1]\n",
        "print(y_pred)\n",
        "#print(y_prob)"
      ],
      "metadata": {
        "id": "g4KmECgwDUcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Intercepto: {model.intercept_}\")\n",
        "print(f\"Coeficientes: {model.coef_}\")\n",
        "print(f\"Acurácia: {accuracy_score(test_y, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "RgehcX7LDo6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature names and coefficients\n",
        "feature_names = X.columns  # <-- uses the real column names\n",
        "coefs = model.coef_[0]     # for binary classification\n",
        "\n",
        "# Build a DataFrame for plotting\n",
        "coef_df = pd.DataFrame({\"Feature\": feature_names, \"Coefficient\": coefs}).sort_values(by=\"Coefficient\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(coef_df[\"Feature\"], coef_df[\"Coefficient\"], color=\"steelblue\")\n",
        "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
        "plt.xlabel(\"Coefficient Value\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Logistic Regression Coefficients\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B7HILYY6F0fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mapping values to binary: hot encoding\n",
        "binary_mapping = {'fire': 1, 'not fire': 0}\n",
        "\n",
        "train_y_bin = train_y.map(binary_mapping)\n",
        "test_y_bin = test_y.map(binary_mapping)\n",
        ""
      ],
      "metadata": {
        "id": "aQXFXiRxeCfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5) Matriz de confusão ===\n",
        "cm = confusion_matrix(test_y, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Matriz de Confusão - Logistic Regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fXECuqJAEajg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y, y_pred, target_names=[\"Not Fire\", \"Fire\"]))"
      ],
      "metadata": {
        "id": "P6nRmvKIMNO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot decision boundary\n",
        "\n",
        "# Create grid for decision surface\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(test_x.iloc[:,7].min(), test_x.iloc[:,7].max(), 200),\n",
        "    np.linspace(test_x.iloc[:,12].min(), test_x.iloc[:,12].max(), 200)\n",
        ")\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# Create a base array with means of all 13 features\n",
        "base = np.tile(train_x.mean().values, (xx.ravel().shape[0], 1))\n",
        "\n",
        "# Replace FFMC and FWI with grid values\n",
        "base[:, 7] = xx.ravel()\n",
        "base[:, 12] = yy.ravel()\n",
        "\n",
        "probs = model.predict_proba(base)[:, 1].reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary line\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.contourf(xx, yy, probs, levels=[0, 0.5, 1], colors=[\"#FFB6C1\", \"#ADD8E6\"], alpha=0.3)\n",
        "plt.scatter(test_x.iloc[:,7], test_x.iloc[:,12], c=test_y_bin, cmap=\"coolwarm\", edgecolors=\"k\", alpha=0.7)\n",
        "plt.contour(xx, yy, probs, levels=[0.5], colors=\"black\")\n",
        "plt.xlabel(\"FFMC\")\n",
        "plt.ylabel(\"FWI\")\n",
        "plt.title(\"Logistic Regression - Fronteira de Decisão (fixing other features at mean)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z14KFYAAH3K5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}